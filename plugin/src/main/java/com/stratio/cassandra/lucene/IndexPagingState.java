package com.stratio.cassandra.lucene;

import com.google.common.base.MoreObjects;
import com.stratio.cassandra.lucene.index.Tuple;
import com.stratio.cassandra.lucene.partitioning.Partitioner;
import com.stratio.cassandra.lucene.search.SearchBuilder;
import com.stratio.cassandra.lucene.util.ByteBufferUtils;
import com.stratio.cassandra.lucene.util.SimplePartitionIterator;
import com.stratio.cassandra.lucene.util.SingleRowIterator;
import org.apache.cassandra.config.DatabaseDescriptor;
import org.apache.cassandra.db.*;
import org.apache.cassandra.db.filter.RowFilter;
import org.apache.cassandra.db.marshal.Int32Type;
import org.apache.cassandra.db.marshal.UTF8Type;
import org.apache.cassandra.db.partitions.PartitionIterator;
import org.apache.cassandra.dht.AbstractBounds;
import org.apache.cassandra.index.Index;
import org.apache.cassandra.service.LuceneStorageProxy;
import org.apache.cassandra.service.pager.PagingState;

import java.lang.reflect.Field;
import java.nio.ByteBuffer;
import java.util.*;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

/**The paging state of a CQL query using Lucene. It tracks the primary keys of the last seen rows
 * for each internal read command of a CQL query. It also keeps the count of the remaining rows.
 * This state can be serialized to be attached to a [[PagingState]] and/or to a search predicate.
 *
 * @author Andres de la Pena `adelapena@stratio.com`
 * @author Artem Martynenko artem7mag@gmai.com
 **/
public class IndexPagingState {

    private static final Field EXPRESSION_VALUE_FIELD;

    static {
        try {
            EXPRESSION_VALUE_FIELD = RowFilter.Expression.class.getDeclaredField("value");
            EXPRESSION_VALUE_FIELD.setAccessible(true);
        } catch (NoSuchFieldException e) {
            throw new IndexException(e);
        }
    }


    /** Returns the paging state represented by the specified byte buffer, which should have been
     * generated with [[IndexPagingState.toByteBuffer]].
     *
     * @param bb a byte buffer generated by [[IndexPagingState.toByteBuffer]]
     * @return the paging state represented by `bb`
     */
    public static IndexPagingState fromByteBuffer(ByteBuffer bb){
        int remaining = bb.getInt();
        IndexPagingState state = new IndexPagingState(remaining);
        for(ByteBuffer byteBuffer: ByteBufferUtils.decompose(bb)){
            ByteBuffer[] values = ByteBufferUtils.decompose(byteBuffer);
            Integer partition = Int32Type.instance.compose(values[0]);
            DecoratedKey key = DatabaseDescriptor.getPartitioner().decorateKey(values[1]);
            Clustering clustering = Clustering.make(Arrays.copyOfRange(values, 2, values.length + 1));
            state.entries.put(new Tuple<>(partition, key), clustering);
        }
        return state;
    }


    /** Returns the Lucene paging state contained in the specified CQL [[PagingState]].
     * If the specified paging state is null, then an empty Lucene paging state will be returned.
     *
     * @param state a CQL paging state
     * @param limit the query user limit
     * @return a Lucene paging state
     */
    public static IndexPagingState build(PagingState state, int limit){
        return state == null ? new IndexPagingState(limit) : fromByteBuffer(state.partitionKey);
    }

    private int remaining;

    /** If there could be more results. */
    private boolean hasMorePages;

    /** The last row positions */
    private LinkedHashMap<Tuple<Integer, DecoratedKey>, Clustering> entries;


    /**
     * @param remaining the number of remaining rows to be retrieved
     * */
    public IndexPagingState(int remaining) {
        this.remaining = remaining;
        this.hasMorePages = true;
        this.entries = new LinkedHashMap<>();
    }




    /** Returns the primary key of the last seen row for the specified read command.
     *
     * @param command a read command
     * @return the primary key of the last seen row for `command`
     */
    public List<Optional<Tuple<Tuple<Integer, DecoratedKey>, Clustering>>>  forCommand(ReadCommand command, Partitioner partitioner){
        return IntStream.range(0, partitioner.numPartitions()).boxed().map(integer -> {
            if(command instanceof SinglePartitionReadCommand){
               return entries.keySet().stream()
                       .filter(intDecKeyTuple -> ((SinglePartitionReadCommand) command).partitionKey().equals(intDecKeyTuple._2) && intDecKeyTuple._1.equals(integer))
                       .findAny()
                       .map(intDecKeyTuple -> new Tuple<>(intDecKeyTuple, entries.get(intDecKeyTuple)));
            } else if(command instanceof PartitionRangeReadCommand) {
                return entries.keySet().stream().filter(intDecKeyTuple -> ((PartitionRangeReadCommand) command).dataRange().contains(intDecKeyTuple._2) && intDecKeyTuple._1.equals(integer))
                        .findAny()
                        .map(intDecKeyTuple -> new Tuple<>(intDecKeyTuple, entries.get(intDecKeyTuple)));
            }else {
                throw new IndexException("Unsupported read command type: {}" , command.getClass());
            }
        }).collect(Collectors.toList());
    }





    /** Adds this paging state to the specified read query.
     *
     * @param query a CQL query using the Lucene index
     * @throws ReflectiveOperationException if there is any problem with reflection
     */
    public void rewrite(ReadQuery query){
        if(query instanceof SinglePartitionReadCommand.Group){
            for(ReadQuery readQuery: ((SinglePartitionReadCommand.Group) query).commands){
                rewrite(readQuery);
            }
        } else if(query instanceof ReadCommand){
            ReadCommand readCommand = (ReadCommand) query;
            RowFilter.Expression expression = indexExpression(readCommand);
            ByteBuffer oldValue = expression.getIndexValue();
            SearchBuilder search = SearchBuilder.fromJson(UTF8Type.instance.compose(oldValue)).paging(this);
            ByteBuffer newValue = UTF8Type.instance.decompose(search.toJson());
            try {
                EXPRESSION_VALUE_FIELD.set(expression, newValue);
            } catch (IllegalAccessException e) {
                throw new IndexException(e);
            }
        }else {
            throw new IndexException("Unsupported query type {}", query.getClass());
        }

    }




    private RowFilter.Expression indexExpression(ReadCommand command){

        // Try with custom expressions
        for(RowFilter.Expression expression: command.rowFilter().getExpressions()){
            if(expression.isCustom()){
                return expression;
            }
        }

        ColumnFamilyStore cfs = Keyspace.open(command.metadata().ksName).getColumnFamilyStore(command.metadata().cfName);
        for(RowFilter.Expression expression: command.rowFilter().getExpressions()){
            for(Index index: cfs.indexManager.listIndexes()){
                if(index instanceof com.stratio.cassandra.lucene.Index && index.supportsExpression(expression.column(), expression.operator())){
                    return expression;
                }
            }
        }
        throw new IndexException("Not found expression");
    }




    /** Updates this paging state with the results of the specified query.
     *
     * @param query       the query
     * @param partitions  the results
     * @param consistency the query consistency level
     * @return a copy of the query results
     */
    public PartitionIterator update(ReadQuery query,
                                    PartitionIterator partitions,
                                    ConsistencyLevel consistency,
                                    Partitioner partitioner){

        if(query instanceof SinglePartitionReadCommand.Group ){
            return update((SinglePartitionReadCommand.Group) query, partitions, partitioner);
        } else if(query instanceof PartitionRangeReadCommand){
            return update((PartitionRangeReadCommand) query, partitions, consistency, partitioner);
        } else {
            throw new IndexException("Unsupported query type {}", query.getClass());
        }
    }

    private PartitionIterator update(SinglePartitionReadCommand.Group group,
                                     PartitionIterator partitions,
                                     Partitioner partitioner){

        List<SingleRowIterator> rowIterators = new ArrayList<>();
        AtomicInteger count = new AtomicInteger(0);
        partitions.forEachRemaining(partition -> {
            DecoratedKey key = partition.partitionKey();
            int p = partitioner.partition(key);

            while (partition.hasNext()){
                SingleRowIterator newRowIterator = new SingleRowIterator(partition);
                rowIterators.add(newRowIterator);
                entries.put(new Tuple<>(p ,key), newRowIterator.row.clustering());
                if(remaining > 0) remaining -= 1;
                count.incrementAndGet();
            }
            partition.close();
        });
        partitions.close();

        hasMorePages = remaining > 0 && count.get() >= group.limits().count();

        return new SimplePartitionIterator(rowIterators);
    }


    private PartitionIterator update(PartitionRangeReadCommand command,
                                     PartitionIterator partitions,
                                     ConsistencyLevel consistency,
                                     Partitioner partitioner){

        LuceneStorageProxy.RangeMerger rangeMerger = LuceneStorageProxy.rangeMerger(command, consistency);
        List<AbstractBounds<PartitionPosition>> bounds = new ArrayList<>();
        rangeMerger.forEachRemaining(rangeForQuery -> bounds.add(rangeForQuery.range));


        List<SingleRowIterator> rowIterators = new ArrayList<>();


        AtomicInteger count = new AtomicInteger(0);

        partitions.forEachRemaining(partition -> {
            DecoratedKey key = partition.partitionKey();
            int p = partitioner.partition(key);
            Optional<AbstractBounds<PartitionPosition>> bound = bounds.stream()
                    .filter(partitionPositionAbstractBounds -> partitionPositionAbstractBounds.contains(key))
                    .findAny();

            while (partition.hasNext()) {

                bound.ifPresent(pPAbstractBounds -> {
                    entries.keySet().stream().filter(intDecKey -> pPAbstractBounds.contains(intDecKey._2) && p == intDecKey._1)
                            .forEach(entries::remove);

                });

                SingleRowIterator newRowIterator = new SingleRowIterator(partition);
                rowIterators.add(newRowIterator);
                Clustering clustering = newRowIterator.row.clustering();
                entries.put(new Tuple<>(p, key), clustering);
                if (remaining > 0) remaining -= 1;
                count.incrementAndGet();
            }
            partition.close();
        });
        partitions.close();

        hasMorePages = remaining > 0 && count.get() >= command.limits().count();

        return new SimplePartitionIterator(rowIterators);
    }


    /** Returns a CQL {@link PagingState} containing this Lucene paging state.
     *
     * @return a CQL paging state
     */
    public PagingState toPagingState(){
        return hasMorePages ? new PagingState(toByteBuffer(), null, remaining, remaining) : null;
    }

    /** Returns a byte buffer representation of this.
     * The returned result can be read with [[fromByteBuffer(ByteBuffer)]].
     *
     * @return a byte buffer representing this
     */
    public ByteBuffer toByteBuffer(){
        ByteBuffer[] entryValues = entries.entrySet().stream().map(tupleClusteringEntry -> {
            ByteBuffer[] clusteringValues = tupleClusteringEntry.getValue().getRawValues();
            ByteBuffer[] values = new ByteBuffer[2 + clusteringValues.length];
            values[0] = Int32Type.instance.decompose(tupleClusteringEntry.getKey()._1);
            values[1] = tupleClusteringEntry.getKey()._2.getKey();
            System.arraycopy(clusteringValues, 0 ,values , 2, clusteringValues.length);
            return ByteBufferUtils.compose(values);
        }).toArray(ByteBuffer[]::new);

        ByteBuffer values = ByteBufferUtils.compose(entryValues);
        ByteBuffer out  = ByteBuffer.allocate(4 + values.remaining());
        out.putInt(remaining).put(values).flip();
        return out;
    }


    @Override
    public String toString() {
        return MoreObjects.toStringHelper(this)
                .add("remaining", remaining)
                .add("entries", entries)
                .add("hasMorePages", hasMorePages)
                .toString();

    }
}
